{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banking Project\n",
    "\n",
    "***\n",
    "\n",
    ">The bank wants to improve their services. For instance, the bank managers have only vague idea, who is a good client (whom to offer some additional services) and who is a bad client (whom to watch carefully to minimize the bank loses). Fortunately, the bank stores data about their clients, the accounts (transactions within several months), the loans already granted, the credit cards issued. The bank managers hope to improve their understanding of customers and seek specific actions to improve services. A mere application of a discovery tool will not be convincing for them.  \n",
    "\n",
    ">To test a data mining approach to help the bank managers, it was decided to address two problems, a descriptive and a predictive one. While the descriptive problem was left open, the predictive problem is the prediction of whether a loan will end successfuly.\n",
    "\n",
    "> _ - in Banking Case Description, ECAC Moodle Page_\n",
    "\n",
    "***\n",
    "\n",
    "[Kaggle Challenge Page](https://www.kaggle.com/)\n",
    "\n",
    "The steps performed are as follows:\n",
    "* Data Loading and Preparation\n",
    "* Descriptive Data Mining & Feature Engineering\n",
    "* Predictive Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "For this work we will use the common tools in a data scientist and engineer arsenal. All of them work together in a seamless fashion, as well as with the Jupyter Notebook (this enhanced interactive document).\n",
    "\n",
    "* **Numpy** is the fundamental package for scientific computing with Python\n",
    "* **Pandas** provides high-performance, easy-to-use data structures (_e.g._ data frames) and data analysis tools\n",
    "* **Matplotlib** implements plotting functionality\n",
    "* **Scikit Learn** aggregates advanced machine learning tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation\n",
    "\n",
    "A key initial step in every data mining work is to prepare the data. This reduces the occurence of future unexpected behaviors and gives a preliminary insight over the \"raw\" data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **transactions** records describe transactions on accounts, representing dynamic characteristics of the accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv('./data/banking - transaction.csv', \n",
    "                              sep=';',\n",
    "                              parse_dates=['date'],\n",
    "                              infer_datetime_format=True,\n",
    "                              dtype={'bank':np.str},\n",
    "                              index_col='trans_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>operation</th>\n",
       "      <th>amount</th>\n",
       "      <th>balance</th>\n",
       "      <th>k_symbol</th>\n",
       "      <th>bank</th>\n",
       "      <th>account</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>695247</th>\n",
       "      <td>2378</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>credit</td>\n",
       "      <td>credit in cash</td>\n",
       "      <td>700</td>\n",
       "      <td>700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171812</th>\n",
       "      <td>576</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>credit</td>\n",
       "      <td>credit in cash</td>\n",
       "      <td>900</td>\n",
       "      <td>900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207264</th>\n",
       "      <td>704</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>credit</td>\n",
       "      <td>credit in cash</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117247</th>\n",
       "      <td>3818</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>credit</td>\n",
       "      <td>credit in cash</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579373</th>\n",
       "      <td>1972</td>\n",
       "      <td>1993-01-02</td>\n",
       "      <td>credit</td>\n",
       "      <td>credit in cash</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          account_id       date    type       operation  amount  balance  \\\n",
       "trans_id                                                                   \n",
       "695247          2378 1993-01-01  credit  credit in cash     700      700   \n",
       "171812           576 1993-01-01  credit  credit in cash     900      900   \n",
       "207264           704 1993-01-01  credit  credit in cash    1000     1000   \n",
       "1117247         3818 1993-01-01  credit  credit in cash     600      600   \n",
       "579373          1972 1993-01-02  credit  credit in cash     400      400   \n",
       "\n",
       "         k_symbol bank  account  \n",
       "trans_id                         \n",
       "695247        NaN  NaN      NaN  \n",
       "171812        NaN  NaN      NaN  \n",
       "207264        NaN  NaN      NaN  \n",
       "1117247       NaN  NaN      NaN  \n",
       "579373        NaN  NaN      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**k_symbol** name is not very represent representative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transactions_df = transactions_df.rename(columns={\n",
    "    'k_symbol': 'trans_char'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>operation</th>\n",
       "      <th>amount</th>\n",
       "      <th>balance</th>\n",
       "      <th>trans_char</th>\n",
       "      <th>bank</th>\n",
       "      <th>account</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>695247</th>\n",
       "      <td>2378</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>credit</td>\n",
       "      <td>credit in cash</td>\n",
       "      <td>700</td>\n",
       "      <td>700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171812</th>\n",
       "      <td>576</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>credit</td>\n",
       "      <td>credit in cash</td>\n",
       "      <td>900</td>\n",
       "      <td>900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207264</th>\n",
       "      <td>704</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>credit</td>\n",
       "      <td>credit in cash</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117247</th>\n",
       "      <td>3818</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>credit</td>\n",
       "      <td>credit in cash</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579373</th>\n",
       "      <td>1972</td>\n",
       "      <td>1993-01-02</td>\n",
       "      <td>credit</td>\n",
       "      <td>credit in cash</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          account_id       date    type       operation  amount  balance  \\\n",
       "trans_id                                                                   \n",
       "695247          2378 1993-01-01  credit  credit in cash     700      700   \n",
       "171812           576 1993-01-01  credit  credit in cash     900      900   \n",
       "207264           704 1993-01-01  credit  credit in cash    1000     1000   \n",
       "1117247         3818 1993-01-01  credit  credit in cash     600      600   \n",
       "579373          1972 1993-01-02  credit  credit in cash     400      400   \n",
       "\n",
       "         trans_char bank  account  \n",
       "trans_id                           \n",
       "695247          NaN  NaN      NaN  \n",
       "171812          NaN  NaN      NaN  \n",
       "207264          NaN  NaN      NaN  \n",
       "1117247         NaN  NaN      NaN  \n",
       "579373          NaN  NaN      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **accounts** records contain static characteristics of the accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accounts_df = pd.read_excel('./data/banking.xlsx', \n",
    "                            sheetname='account',\n",
    "                            parse_dates=['date'],\n",
    "                            infer_datetime_format=True,\n",
    "                            index_col='account_id'\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_id</th>\n",
       "      <th>frequency</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>55</td>\n",
       "      <td>monthly issuance</td>\n",
       "      <td>1993-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>74</td>\n",
       "      <td>monthly issuance</td>\n",
       "      <td>1993-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>55</td>\n",
       "      <td>monthly issuance</td>\n",
       "      <td>1993-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>16</td>\n",
       "      <td>monthly issuance</td>\n",
       "      <td>1993-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>24</td>\n",
       "      <td>monthly issuance</td>\n",
       "      <td>1993-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            district_id         frequency       date\n",
       "account_id                                          \n",
       "576                  55  monthly issuance 1993-01-01\n",
       "3818                 74  monthly issuance 1993-01-01\n",
       "704                  55  monthly issuance 1993-01-01\n",
       "2378                 16  monthly issuance 1993-01-01\n",
       "2632                 24  monthly issuance 1993-01-02"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **clients** records describe static characteristics of the clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clients_df = pd.read_excel('./data/banking.xlsx',\n",
    "                           sheetname='client',\n",
    "                           index_col='client_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birth_number</th>\n",
       "      <th>district_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>706213</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>450204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>406009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>561201</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>605703</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           birth_number  district_id\n",
       "client_id                           \n",
       "1                706213           18\n",
       "2                450204            1\n",
       "3                406009            1\n",
       "4                561201            5\n",
       "5                605703            5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **birth_number** feature is not readable in this representation. We have, then, to parse it and transform it into two new columns: **birthday** and **gender**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clients_df['gender'] = clients_df.apply(lambda c: 'Male' if c['birth_number'] % 10000 < 5000 else 'Female', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "def normalize_birth_number(client):\n",
    "    birth_number = int(client['birth_number'])\n",
    "    year = birth_number // 10000\n",
    "    month = (birth_number // 100) % 100\n",
    "    day = birth_number % 100\n",
    "    \n",
    "    month = month if month < 50 else month - 50\n",
    "    \n",
    "    return  \"{0:02d}{1:02d}{2:02d}\".format(year, month, day)\n",
    "\n",
    "\n",
    "clients_df['birth_number'] = clients_df.apply(normalize_birth_number, axis=1) # month - 50 on females\n",
    "clients_df['birthday'] = pd.to_datetime(clients_df['birth_number'], format='%y%m%d')\n",
    "clients_df['birthday'] = clients_df.apply(\n",
    "    lambda c: c['birthday'] if c['birthday'].date() <= date.today() else (c['birthday'] - pd.tseries.offsets.DateOffset(years=100)), \n",
    "    axis=1) # if infered year > 2015 the it is in the 19's\n",
    "clients_df = clients_df.drop('birth_number', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>Female</td>\n",
       "      <td>1970-12-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>1945-02-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>1940-10-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>1956-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>1960-07-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           district_id  gender   birthday\n",
       "client_id                                \n",
       "1                   18  Female 1970-12-13\n",
       "2                    1    Male 1945-02-04\n",
       "3                    1  Female 1940-10-09\n",
       "4                    5    Male 1956-12-01\n",
       "5                    5  Female 1960-07-03"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **dispositions** records relate a client with an account (being useful in join operations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dispositions_df = pd.read_excel('./data/banking.xlsx',\n",
    "                                sheetname='disposition',\n",
    "                                index_col='disp_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disp_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>OWNER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>OWNER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>DISPONENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>OWNER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>DISPONENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         client_id  account_id       type\n",
       "disp_id                                  \n",
       "1                1           1      OWNER\n",
       "2                2           2      OWNER\n",
       "3                3           2  DISPONENT\n",
       "4                4           3      OWNER\n",
       "5                5           3  DISPONENT"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispositions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **payment_orders** records, like **transaction** records, represent another dynamic characteristic of accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "payment_orders_df = pd.read_excel('./data/banking.xlsx',\n",
    "                                  sheetname='payment order',\n",
    "                                  index_col='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>bank_to</th>\n",
       "      <th>account_to</th>\n",
       "      <th>amount</th>\n",
       "      <th>k_symbol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29401</th>\n",
       "      <td>1</td>\n",
       "      <td>YZ</td>\n",
       "      <td>87144583</td>\n",
       "      <td>2452.0</td>\n",
       "      <td>household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29402</th>\n",
       "      <td>2</td>\n",
       "      <td>ST</td>\n",
       "      <td>89597016</td>\n",
       "      <td>3372.7</td>\n",
       "      <td>loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29403</th>\n",
       "      <td>2</td>\n",
       "      <td>QR</td>\n",
       "      <td>13943797</td>\n",
       "      <td>7266.0</td>\n",
       "      <td>household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29404</th>\n",
       "      <td>3</td>\n",
       "      <td>WX</td>\n",
       "      <td>83084338</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29405</th>\n",
       "      <td>3</td>\n",
       "      <td>CD</td>\n",
       "      <td>24485939</td>\n",
       "      <td>327.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          account_id bank_to  account_to  amount   k_symbol\n",
       "order_id                                                   \n",
       "29401              1      YZ    87144583  2452.0  household\n",
       "29402              2      ST    89597016  3372.7       loan\n",
       "29403              2      QR    13943797  7266.0  household\n",
       "29404              3      WX    83084338  1135.0  household\n",
       "29405              3      CD    24485939   327.0        NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_orders_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **loans** records describe information of a loan for an account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loans_df = pd.read_excel('./data/banking.xlsx',\n",
    "                         sheetname='loan',\n",
    "                         parse_dates=['date'],\n",
    "                         infer_datetime_format=True,\n",
    "                         index_col='loan_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>date</th>\n",
       "      <th>amount</th>\n",
       "      <th>duration</th>\n",
       "      <th>payments</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5314</th>\n",
       "      <td>1787</td>\n",
       "      <td>1993-07-05</td>\n",
       "      <td>96396</td>\n",
       "      <td>12</td>\n",
       "      <td>8033</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5316</th>\n",
       "      <td>1801</td>\n",
       "      <td>1993-07-11</td>\n",
       "      <td>165960</td>\n",
       "      <td>36</td>\n",
       "      <td>4610</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6863</th>\n",
       "      <td>9188</td>\n",
       "      <td>1993-07-28</td>\n",
       "      <td>127080</td>\n",
       "      <td>60</td>\n",
       "      <td>2118</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5325</th>\n",
       "      <td>1843</td>\n",
       "      <td>1993-08-03</td>\n",
       "      <td>105804</td>\n",
       "      <td>36</td>\n",
       "      <td>2939</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7240</th>\n",
       "      <td>11013</td>\n",
       "      <td>1993-09-06</td>\n",
       "      <td>274740</td>\n",
       "      <td>60</td>\n",
       "      <td>4579</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         account_id       date  amount  duration  payments status\n",
       "loan_id                                                          \n",
       "5314           1787 1993-07-05   96396        12      8033      B\n",
       "5316           1801 1993-07-11  165960        36      4610      A\n",
       "6863           9188 1993-07-28  127080        60      2118      A\n",
       "5325           1843 1993-08-03  105804        36      2939      A\n",
       "7240          11013 1993-09-06  274740        60      4579      A"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **credit_cards** records describes static information of a credit card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "credit_cards_df = pd.read_excel('./data/banking.xlsx',\n",
    "                                sheetname='credit card',\n",
    "                                parse_dates=['issued'],\n",
    "                                infer_datetime_format=True,\n",
    "                                index_col='card_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disp_id</th>\n",
       "      <th>type</th>\n",
       "      <th>issued</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>9285</td>\n",
       "      <td>classic</td>\n",
       "      <td>1993-11-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>588</td>\n",
       "      <td>classic</td>\n",
       "      <td>1994-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>4915</td>\n",
       "      <td>classic</td>\n",
       "      <td>1994-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>439</td>\n",
       "      <td>classic</td>\n",
       "      <td>1994-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>3687</td>\n",
       "      <td>classic</td>\n",
       "      <td>1994-02-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         disp_id     type     issued\n",
       "card_id                             \n",
       "1005        9285  classic 1993-11-07\n",
       "104          588  classic 1994-01-19\n",
       "747         4915  classic 1994-02-05\n",
       "70           439  classic 1994-02-08\n",
       "577         3687  classic 1994-02-15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_cards_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **districts** records provide demographic information about a district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "districts_df = pd.read_excel('./data/banking.xlsx',\n",
    "                             sheetname='district',\n",
    "                             index_col='A1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D1</td>\n",
       "      <td>R1</td>\n",
       "      <td>1204953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12541</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.43</td>\n",
       "      <td>167</td>\n",
       "      <td>85677</td>\n",
       "      <td>99107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D2</td>\n",
       "      <td>R2</td>\n",
       "      <td>88884</td>\n",
       "      <td>80</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>46.7</td>\n",
       "      <td>8507</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.85</td>\n",
       "      <td>132</td>\n",
       "      <td>2159</td>\n",
       "      <td>2674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D3</td>\n",
       "      <td>R2</td>\n",
       "      <td>75232</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>41.7</td>\n",
       "      <td>8980</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.21</td>\n",
       "      <td>111</td>\n",
       "      <td>2824</td>\n",
       "      <td>2813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D4</td>\n",
       "      <td>R2</td>\n",
       "      <td>149893</td>\n",
       "      <td>63</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>67.4</td>\n",
       "      <td>9753</td>\n",
       "      <td>4.64</td>\n",
       "      <td>5.05</td>\n",
       "      <td>109</td>\n",
       "      <td>5244</td>\n",
       "      <td>5892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D5</td>\n",
       "      <td>R2</td>\n",
       "      <td>95616</td>\n",
       "      <td>65</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>51.4</td>\n",
       "      <td>9307</td>\n",
       "      <td>3.85</td>\n",
       "      <td>4.43</td>\n",
       "      <td>118</td>\n",
       "      <td>2616</td>\n",
       "      <td>3040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A2  A3       A4  A5  A6  A7  A8  A9    A10    A11   A12   A13  A14    A15  \\\n",
       "A1                                                                              \n",
       "1   D1  R1  1204953   0   0   0   1   1  100.0  12541  0.29  0.43  167  85677   \n",
       "2   D2  R2    88884  80  26   6   2   5   46.7   8507  1.67  1.85  132   2159   \n",
       "3   D3  R2    75232  55  26   4   1   5   41.7   8980  1.95  2.21  111   2824   \n",
       "4   D4  R2   149893  63  29   6   2   6   67.4   9753  4.64  5.05  109   5244   \n",
       "5   D5  R2    95616  65  30   4   1   6   51.4   9307  3.85  4.43  118   2616   \n",
       "\n",
       "      A16  \n",
       "A1         \n",
       "1   99107  \n",
       "2    2674  \n",
       "3    2813  \n",
       "4    5892  \n",
       "5    3040  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "districts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column labels provided lack any useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "districts_df = districts_df.rename(columns={\n",
    "        'A2': 'district_name',\n",
    "        'A3': 'region',\n",
    "        'A4': 'no_inhabitants',\n",
    "        'A5': 'no_municipalities_w_inhabitants_<499',\n",
    "        'A6': 'no_municipalities_w_inhabitants_500-1999',\n",
    "        'A7': 'no_municipalities_w_inhabitants_2000-9999',\n",
    "        'A8': 'no_municipalities_w_inhabitants_>10000',\n",
    "        'A9': 'no_cities',\n",
    "        'A10': 'ratio_urban_inhabitants',\n",
    "        'A11': 'average_salary',\n",
    "        'A12': 'unemployment_rate_95',\n",
    "        'A13': 'unemployment_rate_96',\n",
    "        'A14': 'no_enterpreneurs_per_1000_inhabitants',\n",
    "        'A15': 'no_commited_crimes_95',\n",
    "        'A16': 'no_commited_crimes_96',\n",
    "    })\n",
    "\n",
    "districts_df.index.name = 'district_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_name</th>\n",
       "      <th>region</th>\n",
       "      <th>no_inhabitants</th>\n",
       "      <th>no_municipalities_w_inhabitants_&lt;499</th>\n",
       "      <th>no_municipalities_w_inhabitants_500-1999</th>\n",
       "      <th>no_municipalities_w_inhabitants_2000-9999</th>\n",
       "      <th>no_municipalities_w_inhabitants_&gt;10000</th>\n",
       "      <th>no_cities</th>\n",
       "      <th>ratio_urban_inhabitants</th>\n",
       "      <th>average_salary</th>\n",
       "      <th>unemployment_rate_95</th>\n",
       "      <th>unemployment_rate_96</th>\n",
       "      <th>no_enterpreneurs_per_1000_inhabitants</th>\n",
       "      <th>no_commited_crimes_95</th>\n",
       "      <th>no_commited_crimes_96</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D1</td>\n",
       "      <td>R1</td>\n",
       "      <td>1204953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12541</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.43</td>\n",
       "      <td>167</td>\n",
       "      <td>85677</td>\n",
       "      <td>99107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D2</td>\n",
       "      <td>R2</td>\n",
       "      <td>88884</td>\n",
       "      <td>80</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>46.7</td>\n",
       "      <td>8507</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.85</td>\n",
       "      <td>132</td>\n",
       "      <td>2159</td>\n",
       "      <td>2674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D3</td>\n",
       "      <td>R2</td>\n",
       "      <td>75232</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>41.7</td>\n",
       "      <td>8980</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.21</td>\n",
       "      <td>111</td>\n",
       "      <td>2824</td>\n",
       "      <td>2813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D4</td>\n",
       "      <td>R2</td>\n",
       "      <td>149893</td>\n",
       "      <td>63</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>67.4</td>\n",
       "      <td>9753</td>\n",
       "      <td>4.64</td>\n",
       "      <td>5.05</td>\n",
       "      <td>109</td>\n",
       "      <td>5244</td>\n",
       "      <td>5892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D5</td>\n",
       "      <td>R2</td>\n",
       "      <td>95616</td>\n",
       "      <td>65</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>51.4</td>\n",
       "      <td>9307</td>\n",
       "      <td>3.85</td>\n",
       "      <td>4.43</td>\n",
       "      <td>118</td>\n",
       "      <td>2616</td>\n",
       "      <td>3040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            district_name region  no_inhabitants  \\\n",
       "district_id                                        \n",
       "1                      D1     R1         1204953   \n",
       "2                      D2     R2           88884   \n",
       "3                      D3     R2           75232   \n",
       "4                      D4     R2          149893   \n",
       "5                      D5     R2           95616   \n",
       "\n",
       "             no_municipalities_w_inhabitants_<499  \\\n",
       "district_id                                         \n",
       "1                                               0   \n",
       "2                                              80   \n",
       "3                                              55   \n",
       "4                                              63   \n",
       "5                                              65   \n",
       "\n",
       "             no_municipalities_w_inhabitants_500-1999  \\\n",
       "district_id                                             \n",
       "1                                                   0   \n",
       "2                                                  26   \n",
       "3                                                  26   \n",
       "4                                                  29   \n",
       "5                                                  30   \n",
       "\n",
       "             no_municipalities_w_inhabitants_2000-9999  \\\n",
       "district_id                                              \n",
       "1                                                    0   \n",
       "2                                                    6   \n",
       "3                                                    4   \n",
       "4                                                    6   \n",
       "5                                                    4   \n",
       "\n",
       "             no_municipalities_w_inhabitants_>10000  no_cities  \\\n",
       "district_id                                                      \n",
       "1                                                 1          1   \n",
       "2                                                 2          5   \n",
       "3                                                 1          5   \n",
       "4                                                 2          6   \n",
       "5                                                 1          6   \n",
       "\n",
       "             ratio_urban_inhabitants  average_salary unemployment_rate_95  \\\n",
       "district_id                                                                 \n",
       "1                              100.0           12541                 0.29   \n",
       "2                               46.7            8507                 1.67   \n",
       "3                               41.7            8980                 1.95   \n",
       "4                               67.4            9753                 4.64   \n",
       "5                               51.4            9307                 3.85   \n",
       "\n",
       "             unemployment_rate_96  no_enterpreneurs_per_1000_inhabitants  \\\n",
       "district_id                                                                \n",
       "1                            0.43                                    167   \n",
       "2                            1.85                                    132   \n",
       "3                            2.21                                    111   \n",
       "4                            5.05                                    109   \n",
       "5                            4.43                                    118   \n",
       "\n",
       "            no_commited_crimes_95  no_commited_crimes_96  \n",
       "district_id                                               \n",
       "1                           85677                  99107  \n",
       "2                            2159                   2674  \n",
       "3                            2824                   2813  \n",
       "4                            5244                   5892  \n",
       "5                            2616                   3040  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "districts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check if the types infered by Pandas library are correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "district_name                                 object\n",
       "region                                        object\n",
       "no_inhabitants                                 int64\n",
       "no_municipalities_w_inhabitants_<499           int64\n",
       "no_municipalities_w_inhabitants_500-1999       int64\n",
       "no_municipalities_w_inhabitants_2000-9999      int64\n",
       "no_municipalities_w_inhabitants_>10000         int64\n",
       "no_cities                                      int64\n",
       "ratio_urban_inhabitants                      float64\n",
       "average_salary                                 int64\n",
       "unemployment_rate_95                          object\n",
       "unemployment_rate_96                         float64\n",
       "no_enterpreneurs_per_1000_inhabitants          int64\n",
       "no_commited_crimes_95                         object\n",
       "no_commited_crimes_96                          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "districts_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that **unemployment_rate_95** and **no_commited_crimes_95** are loaded as objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.29', '1.67', '1.95', '4.64', '3.85', '2.95', '2.26', '1.25',\n",
       "       '3.39', '0.56', '0.45', '3.83', '2.77', '1.42', '3.13', '1.12',\n",
       "       '2.38', '2.83', '2.65', '1.51', '1.10', '1.79', '1.39', '2.47',\n",
       "       '2.64', '0.65', '1.62', '2.82', '3.38', '3.52', '2.80', '5.75',\n",
       "       '6.43', '1.02', '3.33', '4.46', '7.08', '7.34', '6.49', '3.32',\n",
       "       '2.41', '1.72', '2.79', '2.28', '1.78', '1.89', '4.83', '2.51',\n",
       "       '2.52', '2.53', '1.60', '1.88', '4.69', '3.73', '3.24', '3.45',\n",
       "       '4.76', '1.29', '3.79', '5.74', '3.51', '5.77', '4.09', '?', '6.63',\n",
       "       '5.93', '3.80', '4.75', '5.38', '4.73', '4.01'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "districts_df['unemployment_rate_95'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([85677, 2159, 2824, 5244, 2616, 2640, 4289, 5179, 2987, 3810, 3475,\n",
       "       3804, 1597, 6604, 1845, 1874, 1003, 1740, 999, 1563, 2299, 1089,\n",
       "       2879, 5198, 1822, 6041, 1029, 1580, 818, 2985, 1328, 4340, 4650,\n",
       "       5323, 3384, 5796, 4147, 2653, 4947, 6949, 6445, 1658, 4085, 2166,\n",
       "       2080, 2854, 6079, 1655, 1660, 2123, 3496, 2564, 1850, 18721, 3659,\n",
       "       3729, 2212, 2595, 1879, 2112, 2719, 1562, 4484, 2157, 2247, 3244,\n",
       "       5623, '?', 9878, 4980, 9672, 4355, 18782, 4063, 3736, 3460], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "districts_df['no_commited_crimes_95'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that both use a question mark to demark missing values. We'll convert properly those columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "district_name                                 object\n",
       "region                                        object\n",
       "no_inhabitants                                 int64\n",
       "no_municipalities_w_inhabitants_<499           int64\n",
       "no_municipalities_w_inhabitants_500-1999       int64\n",
       "no_municipalities_w_inhabitants_2000-9999      int64\n",
       "no_municipalities_w_inhabitants_>10000         int64\n",
       "no_cities                                      int64\n",
       "ratio_urban_inhabitants                      float64\n",
       "average_salary                                 int64\n",
       "unemployment_rate_95                         float64\n",
       "unemployment_rate_96                         float64\n",
       "no_enterpreneurs_per_1000_inhabitants          int64\n",
       "no_commited_crimes_95                        float64\n",
       "no_commited_crimes_96                          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "districts_df['unemployment_rate_95'] = pd.to_numeric(districts_df['unemployment_rate_95'], errors='coerce')\n",
    "districts_df['no_commited_crimes_95'] = pd.to_numeric(districts_df['no_commited_crimes_95'], errors='coerce')\n",
    "\n",
    "districts_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Descriptive Data Mining & Feature Engineering\n",
    "\n",
    "This first section aims at providing ways to better understand and extract value from the data. This is mostly accoplished by gathering descriptive statistics and ploting.\n",
    "\n",
    "Considering this gathered knowledge, the datasets are edited and joined into useful intermediate format, which represent the main entities in the data, and then in a format in which the machine learning algorithms are able to understand (most of the times a single matrix, and most of the times without missing values).\n",
    "\n",
    "The **loans** relate to the remainder entities through the **account** they are linked to. Therefore, the remainder entities should be summarized in such a way that each of the **accounts** information is given in a single row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loans Dataframe\n",
    "\n",
    "We must look first to the loans because we will use the granting date of the loan to select which information is used to summarize the transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>date</th>\n",
       "      <th>amount</th>\n",
       "      <th>duration</th>\n",
       "      <th>payments</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>682.000000</td>\n",
       "      <td>682</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1998-07-12 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1993-07-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1998-12-08 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5824.162757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151410.175953</td>\n",
       "      <td>36.492669</td>\n",
       "      <td>4190.664223</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3283.512681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113372.406310</td>\n",
       "      <td>17.075219</td>\n",
       "      <td>2215.830344</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4980.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2967.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66732.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2477.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5738.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116928.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>3934.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8686.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210654.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>5813.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11362.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>590820.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>9910.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          account_id                 date         amount    duration  \\\n",
       "count     682.000000                  682     682.000000  682.000000   \n",
       "unique           NaN                  559            NaN         NaN   \n",
       "top              NaN  1998-07-12 00:00:00            NaN         NaN   \n",
       "freq             NaN                    4            NaN         NaN   \n",
       "first            NaN  1993-07-05 00:00:00            NaN         NaN   \n",
       "last             NaN  1998-12-08 00:00:00            NaN         NaN   \n",
       "mean     5824.162757                  NaN  151410.175953   36.492669   \n",
       "std      3283.512681                  NaN  113372.406310   17.075219   \n",
       "min         2.000000                  NaN    4980.000000   12.000000   \n",
       "25%      2967.000000                  NaN   66732.000000   24.000000   \n",
       "50%      5738.500000                  NaN  116928.000000   36.000000   \n",
       "75%      8686.000000                  NaN  210654.000000   48.000000   \n",
       "max     11362.000000                  NaN  590820.000000   60.000000   \n",
       "\n",
       "           payments status  \n",
       "count    682.000000    682  \n",
       "unique          NaN      4  \n",
       "top             NaN      C  \n",
       "freq            NaN    403  \n",
       "first           NaN    NaN  \n",
       "last            NaN    NaN  \n",
       "mean    4190.664223    NaN  \n",
       "std     2215.830344    NaN  \n",
       "min      304.000000    NaN  \n",
       "25%     2477.000000    NaN  \n",
       "50%     3934.000000    NaN  \n",
       "75%     5813.500000    NaN  \n",
       "max     9910.000000    NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B' 'A' 'C' 'D']\n"
     ]
    }
   ],
   "source": [
    "print(loans_df.status.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference:\n",
    " * **A-** contract finished, no problems\n",
    " * **B-** contract finished, loan not payed\n",
    " * **C-** running contract, ok so far\n",
    " * **D-** running contract, client in debt\n",
    " \n",
    "Lets  see how the loans distribute accross the four categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "A    203\n",
       "B     31\n",
       "C    403\n",
       "D     45\n",
       "Name: account_id, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_df.groupby('status').count()['account_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also a lot of contracts running, but most importantly there is a gret disparity between the two counts of the different loans results. We must be aware of this when training the algorithms. As we want to identify properly the loans that will have the **B** status, we have to be carefull when structuring the training and testing datasets.\n",
    "\n",
    "In order to summarize this data, we want to obtain the *count* of loans in each state, as well as the *average* and *standard deviation* of the amount and duration associated with each loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B_cnt</th>\n",
       "      <th>B_amount_avg</th>\n",
       "      <th>B_amount_std</th>\n",
       "      <th>B_duration_avg</th>\n",
       "      <th>B_duration_std</th>\n",
       "      <th>A_cnt</th>\n",
       "      <th>A_amount_avg</th>\n",
       "      <th>A_amount_std</th>\n",
       "      <th>A_duration_avg</th>\n",
       "      <th>A_duration_std</th>\n",
       "      <th>C_cnt</th>\n",
       "      <th>C_amount_avg</th>\n",
       "      <th>C_amount_std</th>\n",
       "      <th>C_duration_avg</th>\n",
       "      <th>C_duration_std</th>\n",
       "      <th>D_cnt</th>\n",
       "      <th>D_amount_avg</th>\n",
       "      <th>D_amount_std</th>\n",
       "      <th>D_duration_avg</th>\n",
       "      <th>D_duration_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>80952</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>30276</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30276</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>318480</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110736</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            B_cnt  B_amount_avg  B_amount_std  B_duration_avg  B_duration_std  \\\n",
       "account_id                                                                      \n",
       "2               0             0             0               0               0   \n",
       "19              1         30276             0              12               0   \n",
       "25              0             0             0               0               0   \n",
       "37              0             0             0               0               0   \n",
       "38              0             0             0               0               0   \n",
       "\n",
       "            A_cnt  A_amount_avg  A_amount_std  A_duration_avg  A_duration_std  \\\n",
       "account_id                                                                      \n",
       "2               1         80952             0              24               0   \n",
       "19              0             0             0               0               0   \n",
       "25              1         30276             0              12               0   \n",
       "37              0             0             0               0               0   \n",
       "38              0             0             0               0               0   \n",
       "\n",
       "            C_cnt  C_amount_avg  C_amount_std  C_duration_avg  C_duration_std  \\\n",
       "account_id                                                                      \n",
       "2               0             0             0               0               0   \n",
       "19              0             0             0               0               0   \n",
       "25              0             0             0               0               0   \n",
       "37              0             0             0               0               0   \n",
       "38              1        110736             0              48               0   \n",
       "\n",
       "            D_cnt  D_amount_avg  D_amount_std  D_duration_avg  D_duration_std  \n",
       "account_id                                                                     \n",
       "2               0             0             0               0               0  \n",
       "19              0             0             0               0               0  \n",
       "25              0             0             0               0               0  \n",
       "37              1        318480             0              60               0  \n",
       "38              0             0             0               0               0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_loans(df):\n",
    "    summaries_dfs = []\n",
    "    for tp in df['status'].unique():\n",
    "        tmp_df = df[df['status'] == tp].drop('status', axis=1)\n",
    "        \n",
    "        tmp_grp_df = tmp_df.groupby('account_id').agg([np.count_nonzero, np.average, np.std])\n",
    "        \n",
    "        amount_df = tmp_grp_df['amount']\n",
    "        amount_df = amount_df.rename(columns={'count_nonzero': tp + '_cnt',\n",
    "                                           'average': tp + '_amount_avg',\n",
    "                                           'std': tp + '_amount_std',\n",
    "                                          })\n",
    "        \n",
    "        duration_df = tmp_grp_df['duration']\n",
    "        duration_df = duration_df.drop('count_nonzero', axis='columns')\n",
    "        duration_df = duration_df.rename(columns={'average': tp + '_duration_avg',\n",
    "                                                  'std': tp + '_duration_std',\n",
    "                                                 })\n",
    "        joined_summary_df = amount_df.join(duration_df)\n",
    "        summaries_dfs.append(joined_summary_df)\n",
    "    \n",
    "    # now concatenate the summaries_dfs\n",
    "    summaries_df = pd.concat(summaries_dfs, axis='columns')\n",
    "    return summaries_df\n",
    "\n",
    "\n",
    "loans_summary_df = summarize_loans(loans_df)\n",
    "loans_summary_df = loans_summary_df.fillna(0)\n",
    "loans_summary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets analyse if the history of each account is long enough to be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4115f1f208>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEECAYAAAACvbKkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4115e93ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loans_hist_df = loans_summary_df[['A_cnt', 'B_cnt', 'C_cnt', 'D_cnt']].sum(axis='columns')\n",
    "loans_hist_df.plot(kind='hist', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there are no accounts with more than one loan through time. Therefore, we will not use the loans history of each account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transactions Dataframe\n",
    "\n",
    "As we analyse the transactions dataframe, we must be careful to associate to each loan only the information about transactions that happened before the loan is granted, as future operations may be strictly correlated with the loan status, and we can't use them to train our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>operation</th>\n",
       "      <th>amount</th>\n",
       "      <th>balance</th>\n",
       "      <th>trans_char</th>\n",
       "      <th>bank</th>\n",
       "      <th>account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1056320.000000</td>\n",
       "      <td>1056320</td>\n",
       "      <td>1056320</td>\n",
       "      <td>873206</td>\n",
       "      <td>1056320.000000</td>\n",
       "      <td>1056320.000000</td>\n",
       "      <td>574439</td>\n",
       "      <td>273508</td>\n",
       "      <td>295389.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2191</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1998-06-30 00:00:00</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>withdrawal in cash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>interest credited</td>\n",
       "      <td>QR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9269</td>\n",
       "      <td>634571</td>\n",
       "      <td>434918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183114</td>\n",
       "      <td>22285</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1993-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1998-12-31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2936.867290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5924.145676</td>\n",
       "      <td>38518.330803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45670919.374916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2477.345127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9522.735373</td>\n",
       "      <td>22117.868013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30663396.851208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-41125.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1204.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.900000</td>\n",
       "      <td>22402.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17828584.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2434.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>33143.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45750951.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3660.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6800.000000</td>\n",
       "      <td>49603.625000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72013407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11382.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87400.000000</td>\n",
       "      <td>209637.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99994199.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            account_id                 date        type           operation  \\\n",
       "count   1056320.000000              1056320     1056320              873206   \n",
       "unique             NaN                 2191           3                   5   \n",
       "top                NaN  1998-06-30 00:00:00  withdrawal  withdrawal in cash   \n",
       "freq               NaN                 9269      634571              434918   \n",
       "first              NaN  1993-01-01 00:00:00         NaN                 NaN   \n",
       "last               NaN  1998-12-31 00:00:00         NaN                 NaN   \n",
       "mean       2936.867290                  NaN         NaN                 NaN   \n",
       "std        2477.345127                  NaN         NaN                 NaN   \n",
       "min           1.000000                  NaN         NaN                 NaN   \n",
       "25%        1204.000000                  NaN         NaN                 NaN   \n",
       "50%        2434.000000                  NaN         NaN                 NaN   \n",
       "75%        3660.000000                  NaN         NaN                 NaN   \n",
       "max       11382.000000                  NaN         NaN                 NaN   \n",
       "\n",
       "                amount         balance         trans_char    bank  \\\n",
       "count   1056320.000000  1056320.000000             574439  273508   \n",
       "unique             NaN             NaN                  8      13   \n",
       "top                NaN             NaN  interest credited      QR   \n",
       "freq               NaN             NaN             183114   22285   \n",
       "first              NaN             NaN                NaN     NaN   \n",
       "last               NaN             NaN                NaN     NaN   \n",
       "mean       5924.145676    38518.330803                NaN     NaN   \n",
       "std        9522.735373    22117.868013                NaN     NaN   \n",
       "min           0.000000   -41125.700000                NaN     NaN   \n",
       "25%         135.900000    22402.500000                NaN     NaN   \n",
       "50%        2100.000000    33143.400000                NaN     NaN   \n",
       "75%        6800.000000    49603.625000                NaN     NaN   \n",
       "max       87400.000000   209637.000000                NaN     NaN   \n",
       "\n",
       "                account  \n",
       "count     295389.000000  \n",
       "unique              NaN  \n",
       "top                 NaN  \n",
       "freq                NaN  \n",
       "first               NaN  \n",
       "last                NaN  \n",
       "mean    45670919.374916  \n",
       "std     30663396.851208  \n",
       "min            0.000000  \n",
       "25%     17828584.000000  \n",
       "50%     45750951.000000  \n",
       "75%     72013407.000000  \n",
       "max     99994199.000000  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**type**, **operation** and **trans_char** seem all to represent the same information. Lets evaluate that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: ['credit' 'withdrawal' 'withdrawal in cash']\n"
     ]
    }
   ],
   "source": [
    "print(\"type:\", transactions_df['type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operation: ['credit in cash' 'collection from another bank' 'withdrawal in cash' nan\n",
      " 'remittance to another bank' 'credit card withdrawal']\n"
     ]
    }
   ],
   "source": [
    "print(\"operation:\", transactions_df['operation'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trans_char: [nan 'pension' 'interest credited' 'household' 'statement' ' '\n",
      " 'insurance payment' 'sanction for negative balance' 'loan payment']\n"
     ]
    }
   ],
   "source": [
    "print(\"trans_char:\", transactions_df['trans_char'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**operation** seems irrelevant given **type**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transactions_df_e = transactions_df.drop('operation', axis=1).copy() # 'e' for edited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its also irrelevant the distinction between *withrawal* and *withrawal in cash*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = transactions_df_e['type'] == 'withdrawal in cash'\n",
    "transactions_df_e.ix[mask, 'type'] = ('withdrawal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an additional column to store the signed amount (given by the type of operation), and another with the normalized **signed_amount** value, according to the **balance** previous to the operation (if an operation is the first one, we store 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transactions_df_e['signed_amount'] = transactions_df_e.apply(lambda x: - x['amount'] if x['type'] == 'withdrawal' else x['amount'], axis=1)\n",
    "transactions_df_e['norm_signed_amount'] = transactions_df_e.apply(lambda x: \n",
    "                                                                      0 if (x['balance'] - x['signed_amount']) == 0 \n",
    "                                                                      else x['signed_amount'] / (x['balance'] - x['signed_amount']), \n",
    "                                                                  axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a function that outputs a summary of the transactions dataframe (if date or account are provided, uses information until a given date for a given account), regarding the following aspects:\n",
    "\n",
    " * From **trans_char** we are able to extract if the user is pensionist, or if the user has been sanctioned for negative balance, among other things. We will create an additional table with that information, with the values weighted by the **amount**, indexed by **account_id**.\n",
    "\n",
    " * The **balance** statistics may be relevant to compare with the loan amount, so we'll gather the *min*, *max*, *average* and *standard deviation*.\n",
    " \n",
    " * Regarding **normalized signed amount** and **type** of each operation, we will extract, for each **account**, the *count*, *mean* and *standard deviation* of operation values, as well as *mean* and *standard deviation* of the number of days between each **operation**, grouped by operation **type**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>balance</th>\n",
       "      <th>trans_char</th>\n",
       "      <th>bank</th>\n",
       "      <th>account</th>\n",
       "      <th>signed_amount</th>\n",
       "      <th>norm_signed_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>695247</th>\n",
       "      <td>2378</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>credit</td>\n",
       "      <td>700</td>\n",
       "      <td>700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171812</th>\n",
       "      <td>576</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>credit</td>\n",
       "      <td>900</td>\n",
       "      <td>900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207264</th>\n",
       "      <td>704</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>credit</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117247</th>\n",
       "      <td>3818</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>credit</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579373</th>\n",
       "      <td>1972</td>\n",
       "      <td>1993-01-02</td>\n",
       "      <td>credit</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          account_id       date    type  amount  balance trans_char bank  \\\n",
       "trans_id                                                                   \n",
       "695247          2378 1993-01-01  credit     700      700        NaN  NaN   \n",
       "171812           576 1993-01-01  credit     900      900        NaN  NaN   \n",
       "207264           704 1993-01-01  credit    1000     1000        NaN  NaN   \n",
       "1117247         3818 1993-01-01  credit     600      600        NaN  NaN   \n",
       "579373          1972 1993-01-02  credit     400      400        NaN  NaN   \n",
       "\n",
       "          account  signed_amount  norm_signed_amount  \n",
       "trans_id                                              \n",
       "695247        NaN            700                   0  \n",
       "171812        NaN            900                   0  \n",
       "207264        NaN           1000                   0  \n",
       "1117247       NaN            600                   0  \n",
       "579373        NaN            400                   0  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_df_e.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def summarize_all_transactions(raw_trans_df, account=None, max_date=None):\n",
    "    \n",
    "    trans_df = raw_trans_df.copy()\n",
    "    \n",
    "    #if client specified, filter\n",
    "    if account != None:\n",
    "        trans_df = trans_df[trans_df.account_id == account]\n",
    "    \n",
    "    #if max_date specified, filter\n",
    "    if max_date != None:\n",
    "        trans_df = trans_df[trans_df.date < max_date]\n",
    "    \n",
    "    # remove the rows where an empty string is present\n",
    "    mask = trans_df.trans_char != ' '\n",
    "    transactions_df_e = trans_df.ix[mask]\n",
    "\n",
    "    # select the needed rows from transactions_df\n",
    "    trans_temp_df = trans_df[['account_id', 'trans_char', 'norm_signed_amount']].copy()\n",
    "\n",
    "    # remove the rows containing NaN\n",
    "    trans_temp_df = trans_temp_df.dropna(axis='index')\n",
    "    \n",
    "    # create the dataframe indexed by account_id\n",
    "    accounts_features_df = trans_temp_df[['account_id']].drop_duplicates(subset=['account_id'])\n",
    "    accounts_features_df = accounts_features_df.set_index('account_id')\n",
    "\n",
    "    # create the count columns, corresponding to the data countained in\n",
    "        # pension\n",
    "        # interest credited\n",
    "        # household\n",
    "        # statement\n",
    "        # insurance payment\n",
    "        # sanction for negative balance\n",
    "        # loan payment\n",
    "\n",
    "    def create_trans_count_col(df, val):\n",
    "        new_df = df.ix[df['trans_char'] == val].groupby('account_id').sum()\n",
    "        new_df = new_df.rename(columns={'norm_signed_amount':val})\n",
    "        return new_df\n",
    "\n",
    "    additional_dfs = [create_trans_count_col(trans_temp_df, val) for val in trans_temp_df['trans_char'].unique()]\n",
    "    \n",
    "    if accounts_features_df.empty:\n",
    "        if len(additional_dfs) == 1:\n",
    "            accounts_features_df = additional_dfs[0]\n",
    "        elif len(additional_dfs) > 1:\n",
    "            accounts_features_df = additional_dfs[0].join(additional_dfs[1:])\n",
    "    else:\n",
    "        accounts_features_df = accounts_features_df.join(additional_dfs)\n",
    "    \n",
    "    temp_df = trans_df[['account_id', 'balance']].copy()\n",
    "\n",
    "    balances_summary_df = temp_df.groupby('account_id').agg([np.max, np.min, np.average, np.std])['balance']\n",
    "    balances_summary_df = balances_summary_df.rename(columns={'amax': 'balance_max',\n",
    "                                                              'amin': 'balance_min',\n",
    "                                                              'average': 'balance_avg',\n",
    "                                                              'std': 'balance_std'})\n",
    "    if accounts_features_df.empty:\n",
    "        accounts_features_df = balances_summary_df\n",
    "    else:\n",
    "        accounts_features_df = accounts_features_df.join(balances_summary_df)\n",
    "    \n",
    "    temp_df = trans_df[['account_id', 'type', 'norm_signed_amount', 'date']].copy()\n",
    "    \n",
    "    # sort firstly by account_id, then by date\n",
    "    temp_df = temp_df.sort_values(by=['account_id', 'date'])\n",
    "\n",
    "    #obtain, by row, the previous date\n",
    "    if account != None:\n",
    "        prev_dates = temp_df['date'].shift().fillna(temp_df.iloc[0]['date'])\n",
    "    else:\n",
    "        prev_dates = temp_df.groupby('account_id').apply(lambda x: x['date'].shift().fillna(x.iloc[0]['date'])) \\\n",
    "        .reset_index(level=0)['date']\n",
    "    \n",
    "    delta = temp_df['date'] - prev_dates\n",
    "    delta = delta.astype(\"timedelta64[D]\")\n",
    "    temp_df['date_delta'] = delta\n",
    "    \n",
    "    def summarize_transactions(df):\n",
    "        summaries_dfs = []\n",
    "        for tp in df['type'].unique():\n",
    "            tmp_df = temp_df[temp_df['type'] == tp].drop('type', axis=1)\n",
    "\n",
    "            tmp_grp_df = tmp_df.groupby('account_id').agg([np.count_nonzero, np.average, np.std])\n",
    "            tmp_grp_df.fillna(0)\n",
    "\n",
    "            ops_df = tmp_grp_df['norm_signed_amount']\n",
    "            ops_df = ops_df.rename(columns={'count_nonzero': tp + '_cnt',\n",
    "                                            'average': tp + '_avg',\n",
    "                                            'std': tp + '_std',\n",
    "                                           })\n",
    "\n",
    "            dates_df = tmp_grp_df['date_delta']\n",
    "            dates_df = dates_df.drop('count_nonzero', axis='columns')\n",
    "            dates_df = dates_df.rename(columns={'average': tp + '_dates_avg',\n",
    "                                                'std': tp + '_dates_std',\n",
    "                                               })\n",
    "            joined_summary_df = ops_df.join(dates_df)\n",
    "            summaries_dfs.append(joined_summary_df)\n",
    "\n",
    "        # now concatenate the summaries_dfs\n",
    "        summaries_df = pd.concat(summaries_dfs, axis='columns')\n",
    "        return summaries_df\n",
    "\n",
    "    trans_summaries_df = summarize_transactions(temp_df)\n",
    "    \n",
    "    if accounts_features_df.empty:\n",
    "        accounts_features_df = trans_summaries_df\n",
    "    else:\n",
    "        accounts_features_df = accounts_features_df.join(trans_summaries_df)\n",
    "    \n",
    "    return accounts_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pension</th>\n",
       "      <th>interest credited</th>\n",
       "      <th>household</th>\n",
       "      <th>statement</th>\n",
       "      <th></th>\n",
       "      <th>insurance payment</th>\n",
       "      <th>sanction for negative balance</th>\n",
       "      <th>loan payment</th>\n",
       "      <th>balance_max</th>\n",
       "      <th>balance_min</th>\n",
       "      <th>...</th>\n",
       "      <th>credit_cnt</th>\n",
       "      <th>credit_avg</th>\n",
       "      <th>credit_std</th>\n",
       "      <th>credit_dates_avg</th>\n",
       "      <th>credit_dates_std</th>\n",
       "      <th>withdrawal_cnt</th>\n",
       "      <th>withdrawal_avg</th>\n",
       "      <th>withdrawal_std</th>\n",
       "      <th>withdrawal_dates_avg</th>\n",
       "      <th>withdrawal_dates_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>25.253957</td>\n",
       "      <td>0.297190</td>\n",
       "      <td>-8.458351</td>\n",
       "      <td>-0.048057</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40163.1</td>\n",
       "      <td>800</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0.176215</td>\n",
       "      <td>0.540524</td>\n",
       "      <td>3.075862</td>\n",
       "      <td>4.436407</td>\n",
       "      <td>203</td>\n",
       "      <td>-0.069644</td>\n",
       "      <td>0.064589</td>\n",
       "      <td>8.576355</td>\n",
       "      <td>8.894198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>32.420419</td>\n",
       "      <td>0.296426</td>\n",
       "      <td>-7.261791</td>\n",
       "      <td>-0.046277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34912.8</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0.225633</td>\n",
       "      <td>1.098706</td>\n",
       "      <td>3.834483</td>\n",
       "      <td>4.663710</td>\n",
       "      <td>224</td>\n",
       "      <td>-0.066102</td>\n",
       "      <td>0.053763</td>\n",
       "      <td>7.290179</td>\n",
       "      <td>7.545420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592</th>\n",
       "      <td>32.100401</td>\n",
       "      <td>0.295263</td>\n",
       "      <td>-8.837104</td>\n",
       "      <td>-0.047720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34845.9</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0.223418</td>\n",
       "      <td>0.835975</td>\n",
       "      <td>11.372414</td>\n",
       "      <td>5.379933</td>\n",
       "      <td>206</td>\n",
       "      <td>-0.080290</td>\n",
       "      <td>0.081912</td>\n",
       "      <td>2.592233</td>\n",
       "      <td>3.838030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>26.308708</td>\n",
       "      <td>0.295281</td>\n",
       "      <td>-8.291333</td>\n",
       "      <td>-0.040056</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44853.6</td>\n",
       "      <td>900</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0.183476</td>\n",
       "      <td>0.582654</td>\n",
       "      <td>11.496552</td>\n",
       "      <td>5.299534</td>\n",
       "      <td>213</td>\n",
       "      <td>-0.067519</td>\n",
       "      <td>0.071666</td>\n",
       "      <td>2.455399</td>\n",
       "      <td>3.366613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>33.220426</td>\n",
       "      <td>0.294159</td>\n",
       "      <td>-11.231152</td>\n",
       "      <td>-0.041544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38943.2</td>\n",
       "      <td>800</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0.231135</td>\n",
       "      <td>0.681602</td>\n",
       "      <td>2.579310</td>\n",
       "      <td>3.612611</td>\n",
       "      <td>212</td>\n",
       "      <td>-0.084583</td>\n",
       "      <td>0.090968</td>\n",
       "      <td>8.551887</td>\n",
       "      <td>6.187600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              pension  interest credited  household  statement     \\\n",
       "account_id                                                          \n",
       "2177        25.253957           0.297190  -8.458351  -0.048057  0   \n",
       "1972        32.420419           0.296426  -7.261791  -0.046277  0   \n",
       "3592        32.100401           0.295263  -8.837104  -0.047720  0   \n",
       "576         26.308708           0.295281  -8.291333  -0.040056  0   \n",
       "2357        33.220426           0.294159 -11.231152  -0.041544  0   \n",
       "\n",
       "            insurance payment  sanction for negative balance  loan payment  \\\n",
       "account_id                                                                   \n",
       "2177                        0                              0             0   \n",
       "1972                        0                              0             0   \n",
       "3592                        0                              0             0   \n",
       "576                         0                              0             0   \n",
       "2357                        0                              0             0   \n",
       "\n",
       "            balance_max  balance_min          ...           credit_cnt  \\\n",
       "account_id                                    ...                        \n",
       "2177            40163.1          800          ...                  144   \n",
       "1972            34912.8          400          ...                  144   \n",
       "3592            34845.9          600          ...                  144   \n",
       "576             44853.6          900          ...                  144   \n",
       "2357            38943.2          800          ...                  144   \n",
       "\n",
       "            credit_avg  credit_std  credit_dates_avg  credit_dates_std  \\\n",
       "account_id                                                               \n",
       "2177          0.176215    0.540524          3.075862          4.436407   \n",
       "1972          0.225633    1.098706          3.834483          4.663710   \n",
       "3592          0.223418    0.835975         11.372414          5.379933   \n",
       "576           0.183476    0.582654         11.496552          5.299534   \n",
       "2357          0.231135    0.681602          2.579310          3.612611   \n",
       "\n",
       "            withdrawal_cnt  withdrawal_avg  withdrawal_std  \\\n",
       "account_id                                                   \n",
       "2177                   203       -0.069644        0.064589   \n",
       "1972                   224       -0.066102        0.053763   \n",
       "3592                   206       -0.080290        0.081912   \n",
       "576                    213       -0.067519        0.071666   \n",
       "2357                   212       -0.084583        0.090968   \n",
       "\n",
       "            withdrawal_dates_avg  withdrawal_dates_std  \n",
       "account_id                                              \n",
       "2177                    8.576355              8.894198  \n",
       "1972                    7.290179              7.545420  \n",
       "3592                    2.592233              3.838030  \n",
       "576                     2.455399              3.366613  \n",
       "2357                    8.551887              6.187600  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_features = summarize_all_transactions(transactions_df_e)\n",
    "trans_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now merge with **loans** dataframe, but for each row obtain just the summary for the transactions that happened before the loan granting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loans_transactions_df = loans_df.copy()\n",
    "\n",
    "for i, row in loans_df.iterrows():\n",
    "    temp_df = summarize_all_transactions(transactions_df_e, row['account_id'], row['date'])\n",
    "    loans_transactions_df = loans_transactions_df.merge(temp_df, left_on='account_id', right_index=True, how='left', sort=False)\n",
    "    \n",
    "\n",
    "loans_transactions_df = loans_transactions_df.fillna(0)\n",
    "loans_transactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clients\n",
    "\n",
    "Now we'll take a look at the features that characterize each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clients_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for each user corresponds a district, we'll look into the corresponding table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "districts_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can consider both the individual districts or the regions. \n",
    "In order to evaluate if the generalization for regions is reduces or not some interesting events, we'll use PCA to reduce the dimensionality of the table to two dimensions, therefore making it possible to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "districts_df_e = districts_df.drop(['district_name', 'region'], axis='columns')\n",
    "districts_df_e = districts_df_e.fillna(0)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "districts_reduced = pca.fit_transform(districts_df_e.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "districts_df_e['a'] = districts_reduced[:, 0]\n",
    "districts_df_e['b'] = districts_reduced[:, 1]\n",
    "\n",
    "# convert regions to integers, to use them as colors\n",
    "regions = districts_df.apply(lambda x: x['region'][1], axis='columns').astype(int)\n",
    "\n",
    "districts_df_e.plot(kind='scatter', x='a', y='b', c=regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we conclude that probably it is beneficial to work with districts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clients_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clients_districts_df = pd.merge(clients_df, districts_df.drop(['region', 'district_name'], axis='columns'), left_on='district_id', right_index=True, how='left', sort=False)\n",
    "\n",
    "# we no longer need district_id column\n",
    "clients_districts_df = clients_districts_df.drop('district_id', axis='columns')\n",
    "\n",
    "clients_districts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll merge **Credit Cards** and **Clients** information with the accounts.\n",
    "\n",
    "As there may be multiple credit cards and clients associated with a given account, we have to devise a certain heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dispositions_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dispositions_df.type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we'll simply use the information about the owner of the account.\n",
    "\n",
    "We'll check the data if there is really only one owner per account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dispositions_owners_df = dispositions_df[dispositions_df['type'] == 'OWNER'].drop('type', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "owners_per_account_df = dispositions_owners_df.groupby(['account_id']).count()\n",
    "\n",
    "owners_per_account_df[owners_per_account_df['client_id'] != 1].count(axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now merge **clients** with **accounts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accounts_disp_merge = accounts_df.merge(dispositions_owners_df, left_index=True, right_on='account_id', how='left', sort=False)\n",
    "accounts_disp_merge = accounts_disp_merge.set_index('account_id')\n",
    "\n",
    "\n",
    "accounts_clients_df = accounts_disp_merge.merge(clients_districts_df, left_on='client_id', right_index=True, how='left', sort=False)\n",
    "accounts_clients_df = accounts_clients_df.drop('client_id', axis='columns')\n",
    "\n",
    "accounts_clients_df = accounts_clients_df.fillna(0)\n",
    "\n",
    "accounts_clients_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accounts_loans_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've gathered 55 features to characterize each account, gathering information about the accounts, users (and respective credit cards), transactions and history of loans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predictive Data Mining\n",
    "\n",
    "The above-mentioned accounts-indexed dataframe, combined with the specification of each loan (duration and amount), constitutes all the needed information to train our algorithms.\n",
    "\n",
    "\n",
    "Firstly we have to prepare a dataframe such that the machine-learning algorithms are able to undertand it. In order to accomplish that, we will merge this **accounts_loans_df** dataframe with the original **loans_df** dataframe. For new loans that arive, the process will be the same, therefore we want to encapsulate the process in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accounts_final_df = accounts_clients_df.rename(columns={'date': 'date created'})\n",
    "accounts_final_df['account_id'] = accounts_final_df.index\n",
    "\n",
    "def join_loans_accounts(l_df):\n",
    "    dataset = pd.merge(l_df, accounts_final_df, left_on='account_id', right_index=True, how='left', sort=False)\n",
    "    return dataset\n",
    "\n",
    "dataset = join_loans_accounts(loans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accounts_final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we have to extract the useful rows: the ones with **status** *A* and *B*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_useful_rows(df):\n",
    "    mask = (dataset.status == 'A') | (dataset.status == 'B')\n",
    "    return dataset[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_useful = select_useful_rows(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(dataset.shape)\n",
    "print(dataset_useful.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just have now to convert the timestamp columns to an integer value. We'll use Unix time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_date_cols(df):\n",
    "    new_df = df.copy()\n",
    "    for col in new_df.columns:\n",
    "        if new_df[col].dtype == 'datetime64[ns]':\n",
    "            new_df[col] = new_df[col].astype(np.int64) // 10**9\n",
    "    return new_df\n",
    "            \n",
    "\n",
    "dataset_valid = convert_date_cols(dataset_useful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and convert categorical data in new columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_mask = dataset_valid.columns[dataset_valid.columns != 'status']\n",
    "\n",
    "dataset_valid_num = pd.get_dummies(dataset_valid[features_mask])\n",
    "dataset_valid_num['status'] = dataset_valid['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = dataset_valid_num.columns[dataset_valid_num.columns != 'status']\n",
    "label = 'status'\n",
    "target_names = ['A', 'B']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing classifiers\n",
    "\n",
    "We'll start off by using a **decision tree** as our first machine learning classifier. It has the benefits of working both with continuous and discrete data types, and provides a very natural way to interpret the results it gives.\n",
    "\n",
    "We'll use stratified k-folds cross-validation to prevent overfitting.\n",
    "\n",
    "The next function implements the procedure of, for a given model, it splits the data into train and test sets, and next performs stratified k-fold cross-validation to select an instance of the model that performs best for the corresponding validation set. It returns the score of the classifier in the testing set, as well as the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.base import clone as skl_clone\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def k_fold_model_select(data, features, label, raw_classifiers, n_folds=10, weigh_samples_fn=None): \n",
    "    # weigh_samples_fn is explained below\n",
    "    \n",
    "    # split into training and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[features].values, \n",
    "                                                        data[label].values,\n",
    "                                                        test_size=0.3,\n",
    "                                                        stratify=data[label],\n",
    "                                                        random_state=5)\n",
    "    \n",
    "    \n",
    "    # use stratified k-fold cross validation to select the model\n",
    "    skf = StratifiedKFold(y_train, n_folds=n_folds)\n",
    "\n",
    "    best_classifier = None\n",
    "    best_score = float('-inf')\n",
    "\n",
    "    for train_index, validation_index in skf:\n",
    "        for raw_classifier in raw_classifiers:\n",
    "            classifier = skl_clone(raw_classifier)\n",
    "            classifier = classifier.fit(X_train[train_index], y_train[train_index])\n",
    "\n",
    "            if weigh_samples_fn != None:\n",
    "                y_pred = classifier.predict(X_train[validation_index])\n",
    "                sample_weight = weigh_samples_fn(y_train[validation_index], y_pred)\n",
    "            else:\n",
    "                sample_weight = None\n",
    "\n",
    "            score = classifier.score(X_train[validation_index], y_train[validation_index],\n",
    "                                     sample_weight=sample_weight)\n",
    "\n",
    "            if score > best_score:\n",
    "                best_classifier = classifier\n",
    "                best_score = score\n",
    "    \n",
    "    # compute the confusion matrix\n",
    "    y_pred = best_classifier.predict(X_test)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # now compute the score for the test data of the best found classifier\n",
    "    if weigh_samples_fn != None:\n",
    "        sample_weight = weigh_samples_fn(y_test, y_pred)\n",
    "    else:\n",
    "        sample_weight = None\n",
    "    test_score = best_classifier.score(X_test, y_test, sample_weight=sample_weight)\n",
    "    \n",
    "    # and obtain the classification report\n",
    "    report = classification_report(y_test, y_pred, target_names=target_names, sample_weight=sample_weight)\n",
    "    \n",
    "    return (test_score, report, conf_mat, best_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceding any further, we have to define how the accuracy is measured given this business situation; we have to measure them according to the way we are predicting it in comparison to the ground truth, *i.e.*, according to the position in the confusion matrix.\n",
    "\n",
    "As such, we will use the following weights:\n",
    " * **True Positives:** 1\n",
    " * **False Negatives:** 2\n",
    " * **False Positives:** 1\n",
    " * **True Negatives:** 1\n",
    " \n",
    "This is because we really want to prevent the cases where we label a user as not trustable, when in fact he is trustable, as he most likely will switch bank and kill all the future accumulated profits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weigh_samples(y_true, y_pred):\n",
    "    weights = []\n",
    "    for s_true, s_pred in zip(y_true, y_pred):\n",
    "        if s_true == 'A' and s_pred == 'B':\n",
    "            weights.append(2)\n",
    "        else:\n",
    "            weights.append(1)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier(min_samples_split=20, random_state=0)\n",
    "dtc_score, dtc_rep, dtc_cm, dtc_clf = k_fold_model_select(dataset_valid_num, features, label, [dtc], weigh_samples_fn=weigh_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "import pydot_ng as pydot\n",
    "from IPython.display import Image\n",
    "\n",
    "def display_tree(dtc_classifier):\n",
    "    dot_data = StringIO()  \n",
    "    tree.export_graphviz(dtc_classifier, out_file=dot_data,  \n",
    "                         feature_names=features_mask,\n",
    "                         class_names=target_names,\n",
    "                         filled=True,\n",
    "                         rounded=True,\n",
    "                         special_characters=True)\n",
    "    graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "    return Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_tree(dtc_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other benefit of decision trees is that they detect easily features that overfit the data. In this example, it seems that the balance takes into account the loan amounts, so the tree separates the data among the criteria of the maximum balance for a given account being negative.\n",
    "\n",
    "We'll continue by removing this feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_trim = features[features != 'balance_max']\n",
    "dtc2 = DecisionTreeClassifier(min_samples_split=20, random_state=0)\n",
    "dtc2_score, dtc2_rep, dtc2_cm, dtc2_clf = k_fold_model_select(dataset_valid_num, features_trim, label, [dtc2], weigh_samples_fn=weigh_samples)\n",
    "\n",
    "print(dtc2_rep)\n",
    "display_tree(dtc2_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the tree indicates that the accounts with low withdrawal values (*withdrawal_avg*) (relative to the account's balance) and high number of deposits (*credit_cnt*) are mostly classified as reliable accounts for loans.\n",
    "\n",
    "On the other hand, accounts with higher withdrawal values (also relative to the account's balance), and higher variance in deposits periodicity (*credit_dates_std*) are mostly classified as non-reliable accounts for loans.\n",
    "\n",
    "Let's analyse more deeply these results. For that, we'll use the obtained score in predicting the test set and the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_confusion_matrix(cm):\n",
    "    # Normalize the confusion matrix by row (i.e by the number of samples\n",
    "    # in each class)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    return cm_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Score for best Decision Tree Classifier:\", dtc_score)\n",
    "print(\"Confusion matrix:\", dtc_cm, sep='\\n')\n",
    "print(\"Classification report:\", dtc_rep, sep='\\n')\n",
    "\n",
    "plot_confusion_matrix(normalize_confusion_matrix(dtc_cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things seem prety good: we have a good accuracy, and the plotted confusion matrix shows high percentage of results in the main diagonal!\n",
    "\n",
    "Nonetheless, there are two factors we have to take into account: \n",
    " * As stated before, we have very few examples with label B (unsuccessful loans), and those events, despite unusual, are very costly. Therefore we need to give them higher relevance.\n",
    " * Trustworthy users that are labeled as trustless ones will most likely swithch to a different bank, negating all the future accumulated revenue. As shown by the confusion matrix, one of the users suffers from exactly this fenomena, therefore we must pay attention to that fact.\n",
    "\n",
    "Because of this, we must be pragmatic about these results and perform some changes.\n",
    "\n",
    "In order to gain more insight, we'll continue by testing other classifiers, analysing their ROC curves. \n",
    "\n",
    "Where applicable, we'll also set the weights given to each label to be **balanced**: this way the classifiers take into account the frequency of each class and automatically adjust their behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier(min_samples_split=20, random_state=0, class_weight='balanced')\n",
    "dt_score, dt_rep, dt_cm, dt_clf = k_fold_model_select(dataset_valid_num, features, label, [dt])\n",
    "\n",
    "print(\"Score:\", dt_score)\n",
    "print(\"Confusion matrix:\", dt_cm, sep='\\n')\n",
    "print(\"Classification report:\", dt_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Linear Classifier (Logistic Regression)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced')\n",
    "lr_score, lr_rep, lr_cm, lr_clf = k_fold_model_select(dataset_valid_num, features, label, [lr], weigh_samples_fn=weigh_samples)\n",
    "\n",
    "print(\"Score:\", lr_score)\n",
    "print(\"Confusion matrix:\", lr_cm, sep='\\n')\n",
    "print(\"Classification report:\", lr_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Nearest Neighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(weights='distance')\n",
    "knn_score, knn_rep, knn_cm, knn_clf = k_fold_model_select(dataset_valid_num, features, label, [knn], weigh_samples_fn=weigh_samples)\n",
    "\n",
    "print(\"Score:\", knn_score)\n",
    "print(\"Confusion matrix:\", knn_cm, sep='\\n')\n",
    "print(\"Classification report:\", knn_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (Gaussian Naive Bayes)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb_score, nb_rep, nb_cm, nb_clf = k_fold_model_select(dataset_valid_num, features, label, [nb], weigh_samples_fn=weigh_samples)\n",
    "\n",
    "print(\"Score:\", nb_score)\n",
    "print(\"Confusion matrix:\", nb_cm, sep='\\n')\n",
    "print(\"Classification report:\", nb_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Neural Network (Multi-Layer Perceptron)\n",
    "from sknn.mlp import Classifier as MLPClassifier\n",
    "from sknn.mlp import Layer as MLPLayer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# use a pipeline that first normalizes the data\n",
    "\n",
    "nn = MLPClassifier(\n",
    "    layers=[\n",
    "        MLPLayer(\"Maxout\", units=30, pieces=2),\n",
    "        MLPLayer(\"Softmax\")],\n",
    "    learning_rate=0.000000001,\n",
    "    n_iter=25)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('min/max scaler', MinMaxScaler(feature_range=(0.0, 1.0))),\n",
    "        ('neural network', nn)])\n",
    "\n",
    "nn_score, nn_rep, nn_cm, nn_clf = k_fold_model_select(dataset_valid_num, features, label, [nn], \n",
    "                                                      weigh_samples_fn=weigh_samples)\n",
    "\n",
    "print(\"Score:\", nn_score)\n",
    "print(\"Confusion matrix:\", nn_cm, sep='\\n')\n",
    "print(\"Classification report:\", nn_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll test SVC with different kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SVC (linear kernel)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#svc_linear = SVC(kernel='linear')\n",
    "#svc_linear_score, svc_linear_rep, svc_linear_cm, svc_linear_clf = k_fold_model_select(dataset_valid_num, features, label, [svc_linear],\n",
    "#                                                                        n_folds=2, weigh_samples_fn=weigh_samples)\n",
    "\n",
    "#print(\"Score:\", svc_linear_score)\n",
    "#print(\"Confusion matrix:\", svc_linear_cm, sep='\\n')\n",
    "#print(\"Classification report:\", svc_linear_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVC (sigmoid kernel)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#svc_sigmoid = SVC(kernel='linear')\n",
    "#svc_sigmoid_score, svc_sigmoid_rep, svc_sigmoid_cm, svc_sigmoid_clf = k_fold_model_select(dataset_valid_num, features, label, [svc_sigmoid],\n",
    "#                                                                        n_folds=2, weigh_samples_fn=weigh_samples)\n",
    "\n",
    "#print(\"Score:\", svc_sigmoid_score)\n",
    "#print(\"Confusion matrix:\", svc_sigmoid_cm, sep='\\n')\n",
    "#print(\"Classification report:\", svc_sigmoid_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVC (radial basis function kernel)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#svc_rbf = SVC(kernel='rbf')\n",
    "#svc_rbf_score, svc_rbf_rep, svc_rbf_cm, svc_rbf_clf = k_fold_model_select(dataset_valid_num, features, label, [svc_rbf],\n",
    "#                                                                        n_folds=2, weigh_samples_fn=weigh_samples)\n",
    "\n",
    "#print(\"Score:\", svc_rbf_score)\n",
    "#print(\"Confusion matrix:\", svc_sigmoid_cm, sep='\\n')\n",
    "#print(\"Classification report:\", svc_sigmoid_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll test some ensamble methods:\n",
    "\n",
    "Starting by **AdaBoost**, this algorithm enables to, in each of its iterations, specialize a base classifier for the instances incorrectly classified in the previous iterations. We'll use as base classifier the Decision Tree Classifier, as it is very volatile to the data in which it is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AdaBoost Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ab = AdaBoostClassifier(base_estimator=dt)\n",
    "ab_score, ab_rep, ab_cm, ab_clf = k_fold_model_select(dataset_valid_num, features, label, [ab], weigh_samples_fn=weigh_samples)\n",
    "\n",
    "print(\"Score:\", ab_score)\n",
    "print(\"Confusion matrix:\", ab_cm, sep='\\n')\n",
    "print(\"Classification report:\", ab_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf_score, rf_rep, rf_cm, rf_clf = k_fold_model_select(dataset_valid_num, features, label, [rf], weigh_samples_fn=weigh_samples)\n",
    "\n",
    "print(\"Score:\", rf_score)\n",
    "print(\"Confusion matrix:\", rf_cm, sep='\\n')\n",
    "print(\"Classification report:\", rf_rep, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
